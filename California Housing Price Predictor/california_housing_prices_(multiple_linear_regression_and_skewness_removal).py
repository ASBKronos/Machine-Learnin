# -*- coding: utf-8 -*-
"""California Housing Prices (Multiple Linear Regression and Skewness Removal)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kRd0KWlKW0uwsy1NZCQMjay1v3safxzI
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression

df = pd.read_csv("housing.csv")

df.head()

df.columns

df.info()

df['total_bedrooms'].fillna(df['total_bedrooms'].mean(), inplace=True)

df.info()

df["ocean_proximity"].value_counts()

df.describe()

df.hist(bins = 50, figsize = (20,10))

df.skew()

#High Skewness in All columns except housing_median_age
#We check the correlation matrix
sns.heatmap(df.corr(),annot = True)
plt.show()

# If we log or square root transform to remove skewness,
# we need to be careful that the column should not be highly correlated to the target variable
# Reduce the skewness for only those columns where the correlation with the target is not that great
# Therefore we reduce skewness for longitude, latitude, total rooms, total bedrooms, population, households and median income
# We skip longitude and latitude as they have negative values in them. Therefore np.sqrt will return nan values


df['total_rooms'] = np.sqrt(df['total_rooms'])
df['total_bedrooms'] = np.sqrt(df['total_bedrooms'])
df['population'] = np.sqrt(df['population'])
df['households'] = np.sqrt(df['households'])
df['median_income'] = np.sqrt(df['median_income'])

df.skew()

df.describe()

x = df.iloc[:,:]
x = x.drop("median_house_value",axis = 1)
y = df.iloc[:,-2]
print(y)

df.head()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state = 0)

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
ct = ColumnTransformer(
    transformers=[('onehot', OneHotEncoder(), ['ocean_proximity'])],
    remainder='passthrough'
)
x_train_transformed = ct.fit_transform(x_train)
x_test_transformed = ct.transform(x_test)

one_hot_encoder = ct.named_transformers_['onehot']
categories_encoded = one_hot_encoder.get_feature_names_out(['ocean_proximity'])
print("Encoded Categories:", categories_encoded)

print(x_train_transformed)

lin_regressor = LinearRegression()
lin_regressor.fit(x_train_transformed,y_train)
y_pred = lin_regressor.predict(x_test_transformed)

from sklearn.metrics import r2_score
r2 = r2_score(y_test, y_pred)
print(f"R2 Score is {r2}")

#Adjusted r2 score:
n = len(y_test)
k = x_test.shape[1]
r2_adj = 1-((1-r2)*(n-1)/(n-k-1))
print(r2_adj)

print(x_test['ocean_proximity'].value_counts())

new_data_point = {
    'longitude': np.random.uniform(-124.35, -114.31),
    'latitude': np.random.uniform(32.54, 41.95),
    'housing_median_age': np.random.uniform(1, 52),
    'total_rooms': np.random.uniform(1.5, 198),
    'total_bedrooms': np.random.uniform(1, 80),
    'population': np.random.uniform(1.8, 187),
    'households': np.random.uniform(1, 77),
    'median_income': np.random.uniform(0.71, 3.8),
    'ocean_proximity': 'NEAR BAY'}

new_data_point_df = pd.DataFrame([new_data_point])
new_datapoint_transformed = ct.transform(new_data_point_df)
prediction = lin_regressor.predict(new_datapoint_transformed)
print("Predicted Median House Value:", prediction[0])